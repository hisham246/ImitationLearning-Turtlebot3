#!/usr/bin/env python

# CS6244 Starter Learner 
# This is a very simple learner just to get you started. It is not a good submission.
# It implements some of the specifications listed and uses a simple ridge regressor 
# with odometry as input (you don't really have ground truth odometry in real-life)
# You are completely free to change the structure; I wrote this quickly so, it is
# very unlikely to be the best structure or be bug free. :P


import rospy
from geometry_msgs.msg import Twist, Pose 
from sensor_msgs.msg import LaserScan, Image
from nav_msgs.msg import Odometry
from std_msgs.msg import String, Bool
from cs6244.srv import Mode, ModeResponse

import numpy as np
from sklearn.datasets import load_linnerud
from sklearn.multioutput import MultiOutputRegressor
from sklearn.linear_model import Ridge
import json

import argparse
import os
from collections import deque
import random
from threading import Lock

from model_il import ImitationNet
import model_il
from dataset import ImitationDataset
import torch


# global data msgs
command = None 
laser = None 
pos = None 
image = None

# constants for the mode
IDLE = 0
COLLECT = 1
TRAIN = 2
EXECUTE = 3
CLEARDATA = 4

currmode = None

# constant for trajectory saving file name
num_traj = 0


# Topic Callbacks
def cmdCallback(vel):
	global command
	#rospy.loginfo(rospy.get_caller_id() + "command %s %s", vel.linear, vel.angular)
	command = vel 

	# your code comes here

def expertCmdCallback(vel):
	'''
	Receives and updates the expert planner velocity commands
	'''
	mutex.acquire()
	robot_cmd.linear.x = vel.linear.x
	robot_cmd.angular.z = vel.angular.z
	mutex.release()


def laserCallback(scan):
	global laser
	#rospy.loginfo(rospy.get_caller_id() + "scan %s", scan.ranges)
	laser = scan 
	# your code comes here


def odomCallback(odom):
	global pos
	#rospy.loginfo(rospy.get_caller_id() + "odom %s", odom.pose)
	pos = odom 
	# your code comes here


def cameraCallback(camera):
	global image
	#rospy.loginfo(rospy.get_caller_id() + "image %s", camera.encoding)
	image = camera
	# Do somemore preprocessing here, if any

def expertCallback(msg):
	global currmode
	if msg.data == 'reset':
		# Reset robot pose in gazebo and rviz
		rospy.sleep(1.0)
		pub_reset.publish(True)
		print('Changing mode back to idle.')
		rospy.sleep(0.1)
		# Reset again to make sure reset at the right pose
		pub_reset.publish(True)
		currmode = IDLE

def handleModeChange(m):
	global currmode, pos, laser, image, command

	reqmode = int(m.reqmode)
	if reqmode == COLLECT:
		rospy.loginfo(rospy.get_caller_id() + ": COLLECT MODE")
	elif reqmode == TRAIN:
		rospy.loginfo(rospy.get_caller_id() + ": TRAIN MODE")
	elif reqmode == EXECUTE:
		rospy.loginfo(rospy.get_caller_id() + ": EXECUTE MODE")
	elif reqmode == CLEARDATA:
		rospy.loginfo(rospy.get_caller_id() + ": CLEARDATA MODE")
	elif reqmode == IDLE:
		pos = laser = image = command = None 
		rospy.loginfo(rospy.get_caller_id() + ": IDLE MODE")
	else:
		reqmode = currmode 
		
	currmode = reqmode
	return ModeResponse(currmode)

def recordData2File(D):
	"""
	Process the latest trajectory data by removing all points that the turtlebot is not
	moving and dump the trajectory into a json file.

	Args:
		D {dict} -- the current trajectory data.
	"""
	global num_traj

	# Write to the correct file name
	file_name = "./data/trajectory_" + str(num_traj) + '.json'
	while os.path.exists(file_name):
		num_traj += 1
		file_name = "./data/trajectory_" + str(num_traj) + '.json'

	# Process trajectory data. Remove all datapoints that are zero velocities
	i = 0
	while i < len(D["robot_vel"]):
		if D["robot_vel"][i] == [0.0, 0.0]:
			D["robot_pos"].pop(i)
			D["laser_scan"].pop(i)
			D["robot_vel"].pop(i)
		else:
			i += 1

	# Write to json file
	if len(D["robot_vel"]) > 0:
		with open(file_name, 'w') as fout:
			json.dump(D, fout)
		num_traj += 1

def resetRobotState():
	pub_reset.publish(True)
	rospy.sleep(0.1)
	pub_reset.publish(True)		# Repeat to make sure reset at the right pose


def collect(model, D, slide_window_D):
	global currmode

	# Start the expert planning first and let it run in the background
	pub_expert.publish("dagger")

	# Initialize data for model policy
	test_data = ImitationDataset(is_test=True)

	# Initialize individual sliding windows for pose and laser
	pose_window = deque()
	laser_window = deque()
	for i in range(args.window_length):
		pose_window.append([pos.pose.pose.position.x, 
							pos.pose.pose.position.y,
							pos.pose.pose.orientation.z, 
							pos.pose.pose.orientation.w])
		laser_window.append([laser.ranges])

	# Control robot until robot reached goal state
	while True:
		# Determine whether to use expert or model policy
		if random.random() <= args.beta:
			# Sends expert policy commands
			mutex.acquire()
			pub_cmd.publish(robot_cmd)
			mutex.release()
		else:
			# Run neural network and send the model policy commands
			odom_input = np.array([pose_window])
			laser_scan = np.array([laser_window])
			vel, model = model_il.test(model, test_data, odom_input, laser_scan)
			mutex.acquire()
			robot_cmd.linear.x = vel[0,0]
			robot_cmd.angular.z = vel[0,1]
			print(vel)
			pub_cmd.publish(robot_cmd)
			mutex.release()

		# Update sliding window and D
		if (command is not None) and (pos is not None):
			robot_pos = [pos.pose.pose.position.x, pos.pose.pose.position.y,
						pos.pose.pose.orientation.z, pos.pose.pose.orientation.w]
			robot_vel = [command.linear.x, command.angular.z]

			if len(slide_window_D) == 0:
				for i in range(args.window_length):
					slide_window_D.append([robot_pos, laser.ranges, robot_vel])
			else:
				slide_window_D.append([robot_pos, laser.ranges, robot_vel])
				slide_window_D.popleft()
				pose_window.append(robot_pos)
				laser_window.append([laser.ranges])
				pose_window.popleft()
				laser_window.popleft()
				D["robot_pos"] += [[slide_window_D[j][0] for j in range(args.window_length)]]
				D["laser_scan"] += [[slide_window_D[j][1] for j in range(args.window_length)]]
				D["robot_vel"] += [slide_window_D[-1][2]]

		# Check if goal is reached
		if abs(pos.pose.pose.position.x - 6.0) < 0.1 and \
			abs(pos.pose.pose.position.y + 1.0) < 0.1:
			# Stop the robot
			mutex.acquire()
			robot_cmd.linear.x, robot_cmd.angular.z = 0.0, 0.0
			pub_cmd.publish(robot_cmd)
			mutex.release()
			# Update beta
			args.beta *= args.beta_decay
			# Change mode back to IDLE
			print('Collection done. Going back to IDLE mode.')
			currmode = IDLE
			break

		# Sleep for the remaining time
		rate.sleep()

	# Stop the expert policy path planning
	print('Stopping expert planning.')
	pub_expert.publish('stop')

	return D, slide_window_D, model


def train(model):
	global currmode

	# train neural network
	model = model_il.train(model)
	model.eval()

	# Reset robot to start state
	print("Training round complete. Resetting robot to start")
	resetRobotState()

	# Done training, return to idle
	print("Returning to Idle mode.")
	currmode=IDLE

	return model

def execute(model):
	global currmode


	if os.path.exists(args.model_dir + 'model.pt'):
		model.load(args.model_dir + 'model.pt')
	model = model.to(args.device)
	model.eval()

	test_data = ImitationDataset(is_test=True)

	# Initialize individual sliding windows for pose and laser
	pose_window = deque()
	laser_window = deque()

	# Keep executing until goal is reached
	while True:
		# Preprocess/Update input
		if len(pose_window) == 0:
			for i in range(args.window_length):
				pose_window.append([pos.pose.pose.position.x, 
										pos.pose.pose.position.y,
										pos.pose.pose.orientation.z, 
										pos.pose.pose.orientation.w])
				laser_window.append([laser.ranges])
		else:
			pose_window.append([pos.pose.pose.position.x, 
									pos.pose.pose.position.y,
									pos.pose.pose.orientation.z, 
									pos.pose.pose.orientation.w])
			laser_window.append([laser.ranges])
			pose_window.popleft()
			laser_window.popleft()

		# Run network policy to get control command 
		odom_input = np.array([pose_window])
		laser_scan = np.array([laser_window])
		vel, model = model_il.test(model, test_data, odom_input, laser_scan)
		mutex.acquire()
		robot_cmd.linear.x = vel[0,0]
		robot_cmd.angular.z = vel[0,1]
		print(vel)
		pub_cmd.publish(robot_cmd)
		mutex.release()

		if abs(pos.pose.pose.position.x - 6.0) < 0.2 and \
				abs(pos.pose.pose.position.y + 1.0) < 0.2:
			# Stop the robot
			mutex.acquire()
			robot_cmd.linear.x, robot_cmd.angular.z = 0.0, 0.0
			pub_cmd.publish(robot_cmd)
			mutex.release()
			# Reset robot to start state
			print("Goal is reached. Resetting robot to start")
			resetRobotState()
			# Change mode back to IDLE
			print('Testing round successful. Going back to IDLE mode.')
			currmode = IDLE
			break

		# Sleep for the remaining time
		rate.sleep()


	#done training, return to idle
	currmode=IDLE

def clearDataset():
	# Initialize Dataset D
	D = {'robot_pos': [], 'laser_scan': [], 'robot_vel':[]}
	# Define sliding window to be deque
	slide_window_D = deque()
	return D, slide_window_D


def learner(args):
	# add callbacks
	rospy.Subscriber("cmd_vel", Twist, cmdCallback)
	rospy.Subscriber("scan", LaserScan, laserCallback)
	rospy.Subscriber("odom", Odometry, odomCallback)
	rospy.Subscriber("/camera/rgb/image_raw", Image, cameraCallback)
	rospy.Subscriber("learner_feedback", String, expertCallback)
	rospy.Subscriber("/cmd_vel_temp", Twist, expertCmdCallback)
	rospy.sleep(0.1)	# Wait a short while for subscribers to be ready

	# service handler
	modeservice = rospy.Service('mode_change', Mode, handleModeChange)

	# Initialize model
	model = ImitationNet(control_dim=2, device=args.device)

	# Initialize dataset and sliding window for data recording
	D, slide_window_D = clearDataset()

	# main loop
	while not rospy.is_shutdown():
		if currmode == COLLECT:
			D, slide_window_D, model = collect(model, D, slide_window_D)
		elif currmode == TRAIN:
			model = train(model)
		elif currmode == EXECUTE:
			execute(model)
		else:
			# write data to json file and reset D
			if len(D['robot_pos']) > 0:
				recordData2File(D)
			D, slide_window_D = clearDataset()

		# sleep for the remaining time
		rate.sleep()



if __name__=='__main__':
	parser = argparse.ArgumentParser(description="parse args")
	parser.add_argument('--dagger_iter', type=int, default=40)
	parser.add_argument('--dagger_samples', type=int, default=60)
	parser.add_argument('--beta', type=float, default=0.59049)#1.0)
	parser.add_argument('--beta_decay', type=float, default=0.9)
	parser.add_argument('--window_length', type=int, default=5)
	parser.add_argument('--model_dir', type=str, 
						default='/home/jeffrey/catkin_ws/src/cs6244/models/')
	parser.add_argument('--device', type=str, default='cpu')
	args = parser.parse_args()

	# configure cuda
	if torch.cuda.is_available():
	    print('cuda is available')
	    args.device = torch.device('cuda')
	else:
	    print('cuda is not available')
	    args.device = "cpu"

	rospy.init_node('learner', anonymous=True)

	# add ROS publishers
	pub_reset = rospy.Publisher("reset_robot_pos", Bool, queue_size=10)
	pub_cmd = rospy.Publisher("/cmd_vel", Twist, queue_size=10)
	pub_expert = rospy.Publisher('learner_mode', String, queue_size=10)

	# Initialize cmd vel Twist
	robot_cmd = Twist()

	# Initialize python mutex
	mutex = Lock()

	# Initialize rate for controlling robot and updating observations
	rate = rospy.Rate(10) #Hz

	learner(args)