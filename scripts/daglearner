#!/usr/bin/env python

# This script contains the DAgger algorithm. It repeatedly collects an
# episode of expert demonstrations following DAgger's model-expert policy
# distribution and trains the neural network policy with the aggregated
# dataset after the episode. It also contains a separate execution feature
# that tests the current model in getting the robot from point A to point B.


import rospy
import actionlib
from move_base_msgs.msg import MoveBaseAction, MoveBaseGoal
from geometry_msgs.msg import Twist, Pose, PoseWithCovarianceStamped
from sensor_msgs.msg import LaserScan
from std_msgs.msg import Bool
from cs6244.srv import Mode, ModeResponse

import numpy as np
import json

import argparse
import os
import random

from model_il import ImitationNet
import model_il
import torch


# global data msgs
expert_cmd = None
laser = None 
pos = None 

# constants for the mode
IDLE = 0
COLLECT = 1
TRAIN = 2
EXECUTE = 3

currmode = None

# constant for trajectory saving file name
num_traj = 0



# Topic Callbacks
def expertCmdCallback(vel):
	global expert_cmd
	expert_cmd = vel

def laserCallback(scan):
	global laser
	laser = scan 

def amclCallback(amcl):
	global pos
	pos = amcl

def handleModeChange(m):
	global currmode, pos, laser

	reqmode = int(m.reqmode)
	if reqmode == COLLECT:
		rospy.loginfo(rospy.get_caller_id() + ": COLLECT MODE")
	elif reqmode == TRAIN:
		rospy.loginfo(rospy.get_caller_id() + ": TRAIN MODE")
	elif reqmode == EXECUTE:
		rospy.loginfo(rospy.get_caller_id() + ": EXECUTE MODE")
	elif reqmode == CLEARDATA:
		rospy.loginfo(rospy.get_caller_id() + ": CLEARDATA MODE")
	elif reqmode == IDLE:
		pos = laser = image = command = None 
		rospy.loginfo(rospy.get_caller_id() + ": IDLE MODE")
	else:
		reqmode = currmode 
		
	currmode = reqmode
	return ModeResponse(currmode)

def recordData2File(D):
	"""
	Process the latest trajectory data by removing all points that the turtlebot is not
	moving and dump the trajectory into a json file.
	"""
	global num_traj

	# Write to the correct file name
	file_name = args.data_dir + "trajectory_" + str(num_traj) + '.json'
	while os.path.exists(file_name):
		num_traj += 1
		file_name = args.data_dir + "trajectory_" + str(num_traj) + '.json'

	# Write to json file
	if len(D["robot_vel"]) > 0:
		with open(file_name, 'w') as fout:
			json.dump(D, fout)
		num_traj += 1

def resetRobotState():
	pub_reset.publish(True)
	rospy.sleep(0.1)
	pub_reset.publish(True)		# Repeat to make sure reset at the right pose


def collect(D):
	global currmode, expert_cmd, pos, laser, model

	# Load model again
	if os.path.exists(args.model_dir + 'model.pt'):
		model.load(args.model_dir + 'model.pt')
	model = model.to(args.device)
	model.eval()

	# Start the expert planning first and let it run in the background
	goal = MoveBaseGoal()
	goal.target_pose.header.frame_id = "map"
	goal.target_pose.header.stamp = rospy.Time.now()
	goal.target_pose.pose.position.x = 6.0
	goal.target_pose.pose.position.y = -1.0
	goal.target_pose.pose.orientation.z = 0.7071
	goal.target_pose.pose.orientation.w = -0.7071
	client.send_goal(goal)
	print('starting expert planning')

	# Control robot until robot reached goal state
	while True:
		if expert_cmd is not None:
			# Check if goal is reached
			if (abs(pos.pose.pose.position.x - 6.0) < 0.5 and \
				abs(pos.pose.pose.position.y + 1.0) < 0.1) or \
				(expert_cmd.linear.x == 0.0 and expert_cmd.angular.z == 0.0):
				print('test')
				# Stop the robot
				robot_cmd = Twist()
				robot_cmd.linear.x, robot_cmd.angular.z = 0.0, 0.0
				pub_cmd.publish(robot_cmd)
				# Update beta
				args.beta *= args.beta_decay
				# Stop the expert policy path planning
				print('Stopping expert planning.')
				client.cancel_goal()
				# Reset robot to start state
				print("Demonstration complete. Resetting robot to start")
				resetRobotState()
				# Change mode back to IDLE
				print('Collection done.')
				currmode = IDLE
				break

			# Determine whether to use expert or model policy
			if random.random() <= args.beta:
				# Sends expert policy commands
				print('expert {:10.6f}, {:10.6f}'.format(expert_cmd.linear.x, expert_cmd.angular.z))
				pub_cmd.publish(expert_cmd)
			else:
				# Run neural network and send the model policy commands
				odom_input = np.array([[pos.pose.pose.position.x, 
										pos.pose.pose.position.y,
										pos.pose.pose.position.z,
										pos.pose.pose.orientation.x,
										pos.pose.pose.orientation.y,
										pos.pose.pose.orientation.z,
										pos.pose.pose.orientation.w]])
				laser_scan = np.array([laser.ranges])

				vel = model_il.test(model, odom_input, laser_scan)
				if abs(expert_cmd.linear.x-vel[0,0]) < 0.2 and \
						abs(expert_cmd.angular.z-vel[0,1]) < 0.3:
					robot_cmd = Twist()
					robot_cmd.linear.x = vel[0,0]
					robot_cmd.angular.z = vel[0,1]
					print('model  {:10.6f}, {:10.6f}'.format(robot_cmd.linear.x, robot_cmd.angular.z))
					pub_cmd.publish(robot_cmd)
				else:
					print('model wrong, using expert instead')
					print('expert {:10.6f}, {:10.6f}, {:10.6f}, {:10.6f}'.format(vel[0,0], vel[0,1], expert_cmd.linear.x, expert_cmd.angular.z))
					pub_cmd.publish(expert_cmd)

			# Update D
			robot_pos = [pos.pose.pose.position.x, pos.pose.pose.position.y,
					pos.pose.pose.position.z, pos.pose.pose.orientation.x,
					pos.pose.pose.orientation.y, pos.pose.pose.orientation.z, 
					pos.pose.pose.orientation.w]
			robot_vel = [expert_cmd.linear.x, expert_cmd.angular.z]

			D["robot_pos"] += [robot_pos]
			D["laser_scan"] += [laser.ranges]
			D["robot_vel"] += [robot_vel]

		# Sleep for the remaining time
		rate.sleep()

	return D


def train():
	global currmode, model

	# Load model again
	if os.path.exists(args.model_dir + 'model.pt'):
		model.load(args.model_dir + 'model.pt')
	model = model.to(args.device)

	# train neural network
	model = model_il.train(model, mode='dagger')
	model.eval()

	# Reset robot to start state
	print("Training round complete. Resetting robot to start")
	resetRobotState()

	# Done training, return to idle
	print("Returning to collect mode.")
	currmode=COLLECT

	return model

def execute():
	global currmode, model

	# Load model again
	if os.path.exists(args.model_dir + 'model.pt'):
		model.load(args.model_dir + 'model.pt')
	model = model.to(args.device)
	model.eval()

	# Keep executing until goal is reached
	while True:
		# Run network policy to get control command 
		odom_input = np.array([[pos.pose.pose.position.x, 
								pos.pose.pose.position.y,
								pos.pose.pose.position.z,
								pos.pose.pose.orientation.x, 
								pos.pose.pose.orientation.y, 
								pos.pose.pose.orientation.z, 
								pos.pose.pose.orientation.w]])
		laser_scan = np.array([laser.ranges])

		vel, model = model_il.test(model, odom_input, laser_scan)
		robot_cmd = Twist()
		robot_cmd.linear.x = vel[0,0]
		robot_cmd.angular.z = vel[0,1]
		pub_cmd.publish(robot_cmd)

		if abs(pos.pose.pose.position.x - 6.0) < 1.0 and \
				abs(pos.pose.pose.position.y + 1.0) < 0.3:
			# Stop the robot
			robot_cmd.linear.x, robot_cmd.angular.z = 0.0, 0.0
			pub_cmd.publish(robot_cmd)
			# Reset robot to start state
			print("Goal is reached. Resetting robot to start")
			resetRobotState()
			# Change mode back to IDLE
			print('Testing round successful. Going back to IDLE mode.')
			currmode = IDLE
			break

		# Sleep for the remaining time
		rate.sleep()

	#done training, return to idle
	currmode=IDLE

def clearDataset():
	# Initialize Dataset D
	D = {'robot_pos': [], 'laser_scan': [], 'robot_vel':[]}
	return D



if __name__=='__main__':
	parser = argparse.ArgumentParser(description="parse args")
	parser.add_argument('--beta', type=float, default=1.0)
	parser.add_argument('--beta_decay', type=float, default=0.1)
	parser.add_argument('--model_dir', type=str, 
						default=os.path.expanduser('~')+'/catkin_ws/src/cs6244/models/dagger/')
	parser.add_argument('--data_dir', type=str, 
						default=os.path.expanduser('~')+'/catkin_ws/src/cs6244/data/dagger/')
	parser.add_argument('--device', type=str, default='cpu')
	args = parser.parse_args()

	# Find the correct beta based on the file names
	i = 0
	beta_file = args.data_dir + "trajectory_" + str(i) + '.json'
	while os.path.exists(beta_file):
		i += 1
		beta_file = args.data_dir + "trajectory_" + str(i) + '.json'
	args.beta = args.beta_decay**i
	print(args.beta)

	# configure cuda
	if torch.cuda.is_available():
	    print('cuda is available')
	    args.device = torch.device('cuda')
	else:
	    print('cuda is not available')
	    args.device = "cpu"

	rospy.init_node('daglearner', anonymous=True)

	# service handler
	modeservice = rospy.Service('mode_change', Mode, handleModeChange)

	# add callbacks
	rospy.Subscriber("scan", LaserScan, laserCallback)
	rospy.Subscriber("amcl_pose", PoseWithCovarianceStamped, amclCallback)
	rospy.Subscriber("/cmd_vel_temp", Twist, expertCmdCallback)

	# add ROS publishers
	pub_reset = rospy.Publisher("reset_robot_pos", Bool, queue_size=10)
	pub_cmd = rospy.Publisher("/cmd_vel", Twist, queue_size=10)

	# Initialize move_base SimpleActionClient
	client = actionlib.SimpleActionClient('move_base',MoveBaseAction)
	client.wait_for_server()

	# Initialize rate for controlling robot and updating observations
	rate = rospy.Rate(20) #Hz

	# Initialize model
	model = ImitationNet(control_dim=2, device=args.device)

	# Initialize dataset and sliding window for data recording
	D = clearDataset()

	# main loop
	while not rospy.is_shutdown():
		if currmode == COLLECT:
			D = collect(D)
		elif currmode == TRAIN:
			train()
		elif currmode == EXECUTE:
			execute()
		else:
			# write data to json file and reset D
			if len(D['robot_pos']) > 0:
				recordData2File(D)
				D = clearDataset()
				print('Going to train')
				expert_cmd = None
				currmode = TRAIN
			D = clearDataset()

		# sleep for the remaining time
		rate.sleep()